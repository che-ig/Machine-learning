{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки numpy и pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# импортируем библиотеку datetime для работы с датами\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Задаем некоторые опции библиотеки pandas, которые настраивают вывод\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 10) \n",
    "pd.set_option('display.max_rows', 15)\n",
    "pd.set_option('display.width', 90)\n",
    "\n",
    "# импортируем библиотеку matplotlib для построения графиков\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Исследование CSV-файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "['7/21/2014', '83.46', '83.53', '81.81', '81.93', '2359300']\n",
      "['7/18/2014', '83.3', '83.4', '82.52', '83.35', '4020800']\n",
      "['7/17/2014', '84.35', '84.63', '83.33', '83.63', '1974000']\n",
      "['7/16/2014', '83.77', '84.91', '83.66', '84.91', '1755600']\n",
      "['7/15/2014', '84.3', '84.38', '83.2', '83.58', '1874700']\n"
     ]
    }
   ],
   "source": [
    "# с помощью модуля csv взглянем на первые 5 строк CSV-файла\n",
    "import csv\n",
    " \n",
    "with open('Notebooks/Data/msft.csv') as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    for i, row in enumerate(reader): \n",
    "        print(row)\n",
    "        if(i >= 5):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "4  7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываеми msft.csv в датафрейм\n",
    "msft = pd.read_csv('Notebooks/Data/msft.csv')\n",
    "msft[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Open   High    Low  Close   Volume\n",
       "Date                                          \n",
       "7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# зададим индекс для наших данных. В нашем случае выберем 0 столбец (столбец с датой).\n",
    "msft = pd.read_csv('Notebooks/Data/msft.csv', index_col=0)\n",
    "msft[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open      float64\n",
       "High      float64\n",
       "Low       float64\n",
       "Close     float64\n",
       "Volume      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вывод и спецификаация типа данных (.dtypes)\n",
    "msft.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы принудительно задать тип столбца, воспользуйтесь параметром **dtype**\n",
    "функции pd.read_csv(). Следующий программный код преобразует столбец Volume\n",
    "в тип float64:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date       object\n",
       "Open      float64\n",
       "High      float64\n",
       "Low       float64\n",
       "Close     float64\n",
       "Volume    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# указываем, что столбец Volume должен иметь тип float64\n",
    "msft = pd.read_csv('Notebooks/Data/msft.csv', dtype = {'Volume': np.float64})\n",
    "msft.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Указание имен столбцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        date   open   high    low  close   volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "4  7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# задаем новый набор имен для столбцов\n",
    "# все имеют нижний регистр, header=0 задает строку заголовков\n",
    "df = pd.read_csv(\"Notebooks/Data/msft.csv\",\n",
    "                header=0,\n",
    "                names=['date', 'open', 'high', 'low', 'close', 'volume'])\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Указание конкретных столбцов для загрузки (usecols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           Close\n",
       "Date            \n",
       "7/21/2014  81.93\n",
       "7/18/2014  83.35\n",
       "7/17/2014  83.63\n",
       "7/16/2014  84.91\n",
       "7/15/2014  83.58"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"Notebooks/Data/msft.csv\",\n",
    "                 usecols=['Date', 'Close'],\n",
    "                index_col=['Date'])\n",
    "df2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сохранение датафрейма в CSV-файл\n",
    "С помощью метода <mark>.to_csv()</mark> объект DataFrame можно сохранить в CSV-файл.\n",
    "\n",
    "С помощью параметра **index_label='date'** необходимо указать, что именем индекса будет имя столбца date. В противном случае индекс не получит имени, добавляемого в первую строку файла, и это затруднит правильное чтение данных. \n",
    "**на данный момнет, кажется, нет необходимости задавать поле index_label т.к pandas и так оставляет индкесный столбец вместе с его меткой**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем датафрейм df2 в новый csv-файл\n",
    "# задаем имя индекса как date\n",
    "df2.to_csv('./msft_mofified.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'Close']\n",
      "['7/21/2014', '81.93']\n",
      "['7/18/2014', '83.35']\n",
      "['7/17/2014', '83.63']\n",
      "['7/16/2014', '84.91']\n",
      "['7/15/2014', '83.58']\n"
     ]
    }
   ],
   "source": [
    "# с помощью модуля csv взглянем на первые 5 строк CSV-файла\n",
    "with open('./msft_mofified.csv') as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    for i,row in enumerate(reader):\n",
    "        print(row)\n",
    "        if(i >= 5):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Работа с данными, в которых используются разделители полей\n",
    "Библиотека pandas предлагает функцию <mark>pd.read_table()</mark> для упрощения чтения\n",
    "данных с разделителями полей. В следующем примере эта функция используется\n",
    "для чтения файла данных msft, задав запятую в качестве значения параметра sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['|Date|Open|High|Low|Close|Volume']\n",
      "['0|7/21/2014|83.46|83.53|81.81|81.93|2359300']\n",
      "['1|7/18/2014|83.3|83.4|82.52|83.35|4020800']\n",
      "['2|7/17/2014|84.35|84.63|83.33|83.63|1974000']\n",
      "['3|7/16/2014|83.77|84.91|83.66|84.91|1755600']\n",
      "['4|7/15/2014|84.3|84.38|83.2|83.58|1874700']\n"
     ]
    }
   ],
   "source": [
    "# используем функцию read_table с параметром sep=',', чтобы прочитать CSV-файл\n",
    "df = pd.read_table(\"Notebooks/Data/msft.csv\", sep=',')\n",
    "\n",
    "df.to_csv('./msft_piped.txt', sep='|')\n",
    "# смотрим, как сработал метод\n",
    "with open('./msft_piped.txt') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        print(row)\n",
    "        if (i >= 5):\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обработка загрязненных данных\n",
    "Данные с разделителями полей могут содержать посторонние строки в начале или\n",
    "в конце файла. В качестве примеров можно привести служебную информацию,\n",
    "размещаемую вверху, например номер счета, адреса, сводные данные, размещаемые внизу. Кроме того, бывают случаи, когда данные хранятся в нескольких строках. Эти ситуации могут вызвать ошибки при загрузке данных. Чтобы разрешить\n",
    "такие ситуации, методы <mark>pd.read_csv и pd.read_table()</mark> предлагают некоторые полезные параметры, которые выручат нас.\n",
    "\n",
    "Опции <mark>skiprows и skipfooter</mark> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is fun because the data does not start on the first line', '', '', '', '', '']\n",
      "['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "['', '', '', '', '', '']\n",
      "['And there is space between the header row and data', '', '', '', '', '']\n",
      "['7/21/2014', '83.46', '83.53', '81.81', '81.93', '2359300']\n",
      "['7/18/2014', '83.3', '83.4', '82.52', '83.35', '4020800']\n"
     ]
    }
   ],
   "source": [
    "# смотрим первые 6 строк в файле msft2.csv\n",
    "with open('Notebooks/Data/msft2.csv') as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        print(row)\n",
    "        if(i >= 5):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        Date   Open   High    Low  Close   Volume\n",
       " 0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       " 1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       " 2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       " 3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       " 4  7/15/2014  84.30  84.38  83.20  83.58  1874700,\n",
       "         Date   Open   High    Low  Close   Volume\n",
       " 0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       " 1  7/18/2014  83.30  83.40  82.52  83.35  4020800)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считываем только нужные строки (убираем строки 0, 2, 3)\n",
    "df = pd.read_csv('Notebooks/Data/msft2.csv', skiprows=[0,2,3])\n",
    "\n",
    "# Для игнорирования последних строк файла есть опция skipfooter\n",
    "df2 = pd.read_csv('Notebooks/Data/msft_with_footer.csv', skipfooter=2, engine='python')\n",
    "df[:5], df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Если файл очень большой, а нам нужно прочитать только первые несколько строк,\n",
    "# то для этого есть опция nrows\n",
    "pd.read_csv('Notebooks/Data/msft.csv', nrows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        date   open   high    low  close      vol\n",
       "0   3/3/2014  80.35  81.31  79.91  79.97  5004100\n",
       "1  2/28/2014  82.40  83.42  82.17  83.42  2853200\n",
       "2  2/27/2014  84.06  84.63  81.63  82.00  3676800\n",
       "3  2/26/2014  82.92  84.03  82.43  83.81  2623600\n",
       "4  2/25/2014  83.80  83.80  81.72  83.08  3579100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пропускаем 100 строк, а затем считываем следующие 5 строк.\n",
    "# Т.к мы пропускаем строку с заголовком столбцщв, то необходимо сообщить pandas, чтобы она\n",
    "# не искала заголовки и использовала указанные имена.\n",
    "pd.read_csv(\"Notebooks/Data/msft.csv\", \n",
    "            skiprows=100, \n",
    "            nrows=5,\n",
    "            header=0, # обязаны это задать т.к передаем опцию names\n",
    "            names=['date', 'open', 'high', 'low', 'close', 'vol'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Чтение и запись данных в формате excex\n",
    "\n",
    "Библиотека pandas поддерживает чтение данных в формате Excel 2003 и более\n",
    "поздних форматах с помощью функции pd.read_excel() или класса ExcelFile. **Оба\n",
    "способа используют либо пакет XLRD, либо пакет OpenPyXL, поэтому вам необходимо\n",
    "убедиться в том, что один из них установлен в вашей среде Python**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0 2014-07-21  83.46  83.53  81.81  81.93  2359300\n",
       "1 2014-07-18  83.30  83.40  82.52  83.35  4020800\n",
       "2 2014-07-17  84.35  84.63  83.33  83.63  1974000\n",
       "3 2014-07-16  83.77  84.91  83.66  84.91  1755600\n",
       "4 2014-07-15  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем файл excel\n",
    "# считываем только данные первого рабочего листа\n",
    "# (msft в данном случае)\n",
    "df = pd.read_excel('Notebooks/Data/stocks.xlsx')\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close    Volume\n",
       "0 2014-07-21  94.99  95.00  93.72  93.94  38887700\n",
       "1 2014-07-18  93.62  94.74  93.02  94.43  49898600\n",
       "2 2014-07-17  95.03  95.28  92.57  93.09  57152000\n",
       "3 2014-07-16  96.97  97.10  94.74  94.78  53396300\n",
       "4 2014-07-15  96.80  96.85  95.03  95.32  45477900"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считываем данные рабочего листа aapl\n",
    "aapl = pd.read_excel('Notebooks/Data/stocks.xlsx', sheet_name='aapl')\n",
    "aapl[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним xls-файл в рабочем листе 'MSFT'\n",
    "# т.к для чтения xls файлов мы испльзуем пакет openpyxl, то мы должны его указать в опции engine/\n",
    "df.to_excel('stocks2.xls', engine='openpyxl', sheet_name='MSFT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы **записать несколько датафреймов в один и тот же файл Excel**, по одному\n",
    "объекту DataFrame на каждый рабочий лист, воспользуйтесь объектом **ExcelWriter**\n",
    "и ключевым словом with. ExcelWriter является частью библиотеки pandas, однако\n",
    "вам нужно убедиться в том, что он импортирован, поскольку данный объект от-\n",
    "сутствует в пространстве имен верхнего уровня библиотеки pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Записываем несколько рабочих листов\n",
    "# требуется класс ExcelWriter\n",
    "# необходимо указать engine, иначе не будет работать.\n",
    "with pd.ExcelWriter('all_stocks.xls', engine='openpyxl') as writer:\n",
    "    aapl.to_excel(writer, engine='openpyxl', sheet_name='AAPL')\n",
    "    df.to_excel(writer, engine='openpyxl', sheet_name='MSFT')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Чтение и запись JSON-файлов\n",
    "\n",
    "Библиотека pandas может читать и записывать данные, хранящиеся в формате JavaScript Object Notation (JSON)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Close': {'0': 81.93, '1': 83.35, '2': 83.63, '3': 84.91, '4': 83.58},\n",
      " 'Date': {'0': 1405900800000,\n",
      "          '1': 1405641600000,\n",
      "          '2': 1405555200000,\n",
      "          '3': 1405468800000,\n",
      "          '4': 1405382400000},\n",
      " 'High': {'0': 83.53, '1': 83.4, '2': 84.63, '3': 84.91, '4': 84.38},\n",
      " 'Low': {'0': 81.81, '1': 82.52, '2': 83.33, '3': 83.66, '4': 83.2},\n",
      " 'Open': {'0': 83.46, '1': 83.3, '2': 84.35, '3': 83.77, '4': 84.3},\n",
      " 'Volume': {'0': 2359300,\n",
      "            '1': 4020800,\n",
      "            '2': 1974000,\n",
      "            '3': 1755600,\n",
      "            '4': 1874700}}\n"
     ]
    }
   ],
   "source": [
    "# записываем данные Excel в JSON-файл\n",
    "df[:5].to_json('stocks.json')\n",
    "\n",
    "# теперь посмотим на json файл\n",
    "import json\n",
    "\n",
    "# модуль для красивого вывода структурированных данных.\n",
    "from pprint import pprint\n",
    "\n",
    "with open('stocks.json') as data_file:\n",
    "    data = json.load(data_file)\n",
    "\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные в формате JSON можно прочитать с помощью функции pd.read_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0 2014-07-21  83.46  83.53  81.81  81.93  2359300\n",
       "1 2014-07-18  83.30  83.40  82.52  83.35  4020800\n",
       "2 2014-07-17  84.35  84.63  83.33  83.63  1974000\n",
       "3 2014-07-16  83.77  84.91  83.66  84.91  1755600\n",
       "4 2014-07-15  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считываем данные в формате JSON\n",
    "df_from_json = pd.read_json('stocks.json')\n",
    "df_from_json[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Чтение HTML-файлов из интернета\n",
    "Библиотека pandas поддерживает чтение HTML-файлов (или HTML-файлов с URL-адресов). Внутри библиотека pandas использует пакеты LXML, Html5Lib и BeautifulSoup4. Эти пакеты предлагают впечатляющие возможности для чтения и записи HTML-таблиц.\n",
    "\n",
    "Стандартный дистрибутив Anaconda может не включать эти пакеты. Если вы\n",
    "получаете ошибку, то, исходя из ее содержания, установите соответствующую\n",
    "библиотеку при помощи Anaconda Navigator. \n",
    "\n",
    "Кроме того, вы можете использовать pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Bank Name          City\n",
      "0                   Pulaski Savings Bank       Chicago\n",
      "1     The First National Bank of Lindsay       Lindsay\n",
      "2  Republic First Bank dba Republic Bank  Philadelphia\n",
      "3                          Citizens Bank      Sac City\n",
      "4               Heartland Tri-State Bank       Elkhart\n"
     ]
    }
   ],
   "source": [
    "# Для иллюстрации мы считаем данные, представляющие собой список банков-\n",
    "# банкротов, опубликованный на сайте Федеральной корпорации по страхованию\n",
    "# вкладов по адресу https://www.fdic.gov/bank/individual/failed/banklist.html. \n",
    "# Просмотрев страницу, можно увидеть, что список обанкротившихся банков довольно внушителен.\n",
    "\n",
    "# import requests\n",
    "\n",
    "# задаем URL-адрес HTML-файла\n",
    "url = \"https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/\"\n",
    "\n",
    "# Можем воспользоваться пакетом resquests\n",
    "# response = requests.get(url)\n",
    "\n",
    "# читаем его\n",
    "banks = pd.read_html(url)\n",
    "# banks_2 = pd.read_html(response.content)\n",
    "\n",
    "# проверяем как было прочитана часть первой таблицы\n",
    "print(banks[0][0:5].iloc[:,0:2], end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода **.to_html()** объект DataFrame можно записать в HTML-файл.\n",
    "Этот метод создает файл, содержащий тег **\\<table\\>** для данных (а не весь HTML-\n",
    "документ). Следующий программный код записывает ранее прочитанные нами\n",
    "данные о котировках акций в HTML-файл и выводит полученный результат\n",
    "в браузере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считываем данные о котировках акций\n",
    "df = pd.read_excel('Notebooks/Data/stocks.xlsx')\n",
    "\n",
    "# Записываем первые 2 строки в HTML\n",
    "df.head(2).to_html('stocks.html')\n",
    "\n",
    "# Смотрим результат в браузере\n",
    "import webbrowser\n",
    "# webbrowser.open('./stocks.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Чтение и запись HDF5-файлов\n",
    "\n",
    "HDF5 – это модель данных, библиотека и файловый формат для хранения\n",
    "и управления данными. Он широко используется в научных вычислительных\n",
    "средах. HDF5 поддерживает неограниченное количество типов данных и предназначен для гибкого и эффективного ввода-вывода, а также для больших\n",
    "и сложных данных... **(стр. 180)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.io.pytables.HDFStore'>\n",
       "File path: Notebooks/Data/store.h5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# задаем стартовое значение генератора случайных чисел\n",
    "# для получения воспроизводимых результатов\n",
    "np.random.seed(123456)\n",
    "        \n",
    "# создаем датафрейм, состоящий из дат и случайных чисел, записанных в трех столбцах\n",
    "df = pd.DataFrame(np.random.randn(8, 3),\n",
    "                index=pd.date_range('1/1/2000', periods=8),\n",
    "                columns=['A', 'B', 'C'])\n",
    "\n",
    "# создаем хранилище HDF5\n",
    "store = pd.HDFStore('Notebooks/Data/store.h5')\n",
    "\n",
    "# Создаем файлы только один раз (поэтому код и закомментирован т.к файлы уже есть)\n",
    "# with pd.HDFStore('my_first_hdf5.h5', 'w', driver=\"H5FD_CORE\") as f:\n",
    "#     f['test'] = pd.DataFrame(np.random.rand(3, 5))\n",
    "\n",
    "# with pd.HDFStore('second_hdf5.h5', 'w', driver=\"H5FD_CORE\") as f:\n",
    "#     f['test'] = pd.DataFrame(np.random.rand(4, 4))\n",
    "\n",
    "store['df'] = df # сохранение произошло здесь\n",
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                   A         B         C\n",
       " 2000-01-01  0.469112 -0.282863 -1.509059\n",
       " 2000-01-02 -1.135632  1.212112 -0.173215\n",
       " 2000-01-03  0.119209 -1.044236 -0.861849\n",
       " 2000-01-04 -2.104569 -0.494929  1.071804\n",
       " 2000-01-05  0.721555 -0.706771 -1.039575,\n",
       "           0         1         2         3         4\n",
       " 0  0.340445  0.984729  0.919540  0.037772  0.861549\n",
       " 1  0.753569  0.405179  0.343526  0.170917  0.394659\n",
       " 2  0.641666  0.274592  0.462354  0.871372  0.401131,\n",
       "           0         1         2         3\n",
       " 0  0.610588  0.117967  0.702184  0.414034\n",
       " 1  0.342345  0.595925  0.199864  0.099737\n",
       " 2  0.734596  0.016545  0.481385  0.095939\n",
       " 3  0.497306  0.838796  0.897333  0.732592)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считываем данные хранилища HDF5\n",
    "store = pd.HDFStore('Notebooks/Data/store.h5')\n",
    "\n",
    "\n",
    "store_read = pd.HDFStore('my_first_hdf5.h5')\n",
    "store_second = pd.HDFStore('second_hdf5.h5')\n",
    "\n",
    "df = store['df']\n",
    "df[:5], store_read['test'], store_second['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка CSV-файлов из интернета\n",
    "\n",
    "Очень часто нужно прочитать данные из интернета. Библиотека pandas упрощает\n",
    "чтение данных из интернета. Все функции pandas, которые мы рассмотрели, позволяют задать URL-адрес, FTP-адрес или S3-адрес вместо локального пути к файлу, и все они работают так же, как работают с локальным файлом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Country  Region\n",
       "0   Algeria  AFRICA\n",
       "1    Angola  AFRICA\n",
       "2     Benin  AFRICA\n",
       "3  Botswana  AFRICA\n",
       "4   Burkina  AFRICA"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем csv непосредственно по URL-адресу\n",
    "countries = pd.read_csv('https://raw.githubusercontent.com/cs109/2014_data/master/countries.csv')\n",
    "countries[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Чтение из базы данных SQL и запись в базу данных SQL\n",
    "Библиотека pandas может считать данные из любой базы данных SQL, которая\n",
    "поддерживает адаптеры данных Python в рамках интерфейса Python DB-API. Чтение выполняется с помощью функции <mark>pandas.io.sql.read_sql()</mark>, а запись в базу дан-\n",
    "ных SQL – с помощью метода <mark>.to_sql()</mark> объекта DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для иллюстрации следующий программный код считывает данные о котировках акций из файлов msft.csv и aapl.csv. Затем он подключается к файлу базы данных SQLite3. **Если файл не существует, он создается «на лету»**. Затем программный код записывает данные MSFT в таблицу под названием STOCK_DATA. **Если таблица не существует, она также будет создана**. Если она уже существует, все данные заменяются данными MSFT. Наконец, программный код добавляет в эту таблицу данные\n",
    "о котировках AAPL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеку SQLite\n",
    "import sqlite3\n",
    "\n",
    "# считываем данные о котировках акций из CSV-файла\n",
    "msft = pd.read_csv('Notebooks/Data/msft.csv')\n",
    "msft['Symbol'] = 'MSFT'\n",
    "aapl = pd.read_csv('Notebooks/Data/aapl.csv')\n",
    "aapl['Symbol'] = 'AAPL'\n",
    "\n",
    "# создаем подключение\n",
    "connection = sqlite3.connect('Notebooks/Data/stocks.sqlite')\n",
    "# .to_sql() создаст базу SQL для храниения датафрейма в указанной таблице. if_exists задает\n",
    "# действие, которое нужно выполнить в том случае, если таблица уже существует.\n",
    "msft.to_sql('STOCK_DATA', connection, if_exists='replace')\n",
    "aapl.to_sql('STOCK_DATA', connection, if_exists='append')\n",
    "\n",
    "# подтверждаем отправку данных в базу и закрываем подключение\n",
    "connection.commit()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Date   Open   High    Low  Close   Volume Symbol\n",
       "index                                                       \n",
       "0      7/21/2014  83.46  83.53  81.81  81.93  2359300   MSFT\n",
       "1      7/18/2014  83.30  83.40  82.52  83.35  4020800   MSFT\n",
       "2      7/17/2014  84.35  84.63  83.33  83.63  1974000   MSFT\n",
       "3      7/16/2014  83.77  84.91  83.66  84.91  1755600   MSFT\n",
       "4      7/15/2014  84.30  84.38  83.20  83.58  1874700   MSFT"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# подключаемся к файлу базы данных\n",
    "connection = sqlite3.connect('Notebooks/Data/stocks.sqlite')\n",
    "\n",
    "# запрос всех записей в STOCK_DATA возвращает датафрейм\n",
    "# index_col задает столбец, который нужно сделать индексом датафрейма\n",
    "stocks = pd.io.sql.read_sql('SELECT * FROM STOCK_DATA;', connection, index_col='index')\n",
    "\n",
    "# закрываем подключение\n",
    "connection.close()\n",
    "\n",
    "# выводим первые 5 наблюдений в извлеченных данных\n",
    "stocks[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка данных с удаленных сервисов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем пакет pandas_datareader\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "import pandas_datareader as pdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные FRED можно получить с помощью класса FredReader, передав определенную\n",
    "метку временного ряда в качестве параметра name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  GDP\n",
       "DATE                 \n",
       "2012-01-01  16068.805\n",
       "2012-04-01  16207.115\n",
       "2012-07-01  16319.541\n",
       "2012-10-01  16420.419\n",
       "2013-01-01  16648.189"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем данные по GDP (это ВВП) из FRED\n",
    "gdp = pdr.data.FredReader('GDP', date(2012, 1, 1), date(2014, 1, 27))\n",
    "gdp.read()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            A576RC1A027NBEA\n",
       "DATE                       \n",
       "1929-01-01             50.5\n",
       "1930-01-01             46.2\n",
       "1931-01-01             39.2\n",
       "1932-01-01             30.5\n",
       "1933-01-01             29.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем данные по показателю Compensation of employees: Wages and salaries\n",
    "pdr.data.FredReader(\"A576RC1A027NBEA\", date(1929, 1, 1), date(2013, 1, 1)).read()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка данных Всемирного банка\n",
    "\n",
    "Тысячи источников информации доступны в рамках базы данных Всемирного\n",
    "банка, и их можно непосредственно прочитать в объект DataFrame библиотеки pandas. C каталогом данных Всемирного банка можно ознакомиться по адресу http://www.worldbank.org/.\n",
    "\n",
    "Наборы данных Всемирного банка идентифицируются с помощью индикато-\n",
    "ров, текстового кода, представляющего каждый набор данных. Полный список\n",
    "индикаторов можно получить с помощью функции <mark>pandas.io.wb.get_indicators()</mark>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     id                                     name\n",
       "0    1.0.HCount.1.90usd          Poverty Headcount ($1.90 a day)\n",
       "1     1.0.HCount.2.5usd          Poverty Headcount ($2.50 a day)\n",
       "2  1.0.HCount.Mid10to50    Middle Class ($10-50 a day) Headcount\n",
       "3       1.0.HCount.Ofcl  Official Moderate Poverty Rate-National\n",
       "4   1.0.HCount.Poor4uds             Poverty Headcount ($4 a day)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas_datareader import wb\n",
    "all_indicators = pdr.wb.get_indicators()\n",
    "\n",
    "# # выводим первые 5 индикаторов (ограничимся выводом только 2 столбцами)\n",
    "all_indicators.iloc[:5, :2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти индикаторы можно посмотреть на веб-сайте Всемирного банка, но \n",
    "**если вы знаете, какой индикатор вам нужен, можно просто выполнить поиск**. В качестве\n",
    "примера следующий программный код использует функцию <mark>wb.search()</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   id                                               name\n",
       "16001     SE.SCH.LIFE  School life expectancy, primary to tertiary, b...\n",
       "16002  SE.SCH.LIFE.FE  School life expectancy, primary to tertiary, f...\n",
       "16003  SE.SCH.LIFE.MA  School life expectancy, primary to tertiary, m..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# поиск индикаторов, связанных с продолжительностью жизни\n",
    "le_indicators = pdr.wb.search('life expectancy')\n",
    "# выводим первые три строки и первые два столбца\n",
    "le_indicators.iloc[:3, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый индикатор разбит по странам. Полный список по странам можно получить с помощью функции <mark>wb.get_countries()</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                          name capitalCity iso2c\n",
       "0                        Aruba  Oranjestad    AW\n",
       "1  Africa Eastern and Southern                ZH\n",
       "2                  Afghanistan       Kabul    AF\n",
       "3                       Africa                A9\n",
       "4   Africa Western and Central                ZI\n",
       "5                       Angola      Luanda    AO"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем список стран, показываем код и название\n",
    "countries = pdr.wb.get_countries()\n",
    "\n",
    "# получаем список стран, показываем код и название\n",
    "countries.loc[0:5, ['name', 'capitalCity', 'iso2c']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные по каждому индикатору можно загрузить с помощью функции\n",
    "<mark>wb.download()</mark>, указав с помощью параметра indicator набор данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                    SP.DYN.LE00.IN\n",
       " country       year                \n",
       " Canada        2014       81.784390\n",
       "               2013       81.744878\n",
       "               2012       81.663659\n",
       "               2011       81.482683\n",
       "               2010       81.322195\n",
       " ...                            ...\n",
       " United States 1984       74.563415\n",
       "               1983       74.463415\n",
       "               1982       74.360976\n",
       "               1981       74.009756\n",
       "               1980       73.609756\n",
       " \n",
       " [105 rows x 1 columns],\n",
       " Index(['Canada', 'Mexico', 'United States'], dtype='object', name='country'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# отключаем предупреждения\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# получаем данные о продолжительности жизни для всех стран с 1980 по 2014 год\n",
    "le_data_all = wb.download(indicator='SP.DYN.LE00.IN', start=1980, end=2014, errors='raise')\n",
    "\n",
    "# по умолчанию будут возвращены данные для сша, канады, мексики (это можно увидеть, посмотрев индекс)\n",
    "le_data_all, le_data_all.index.levels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы получить данные для большего количества стран, укажите их явно, воспользовавшись параметром **country**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      SP.DYN.LE00.IN\n",
       " year                \n",
       " 2023             NaN\n",
       " 2022       72.545610\n",
       " 2021       69.900244\n",
       " 2020       71.338780\n",
       " 2019       73.083902\n",
       " ...              ...\n",
       " 1984       67.202683\n",
       " 1983       67.652683\n",
       " 1982       67.806098\n",
       " 1981       67.263902\n",
       " 1980       67.033902\n",
       " \n",
       " [44 rows x 1 columns],)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем данные о продолжительности жизни для всех стран с 1980 по 2024 год\n",
    "le_data_all = wb.download(indicator=\"SP.DYN.LE00.IN\",\n",
    "                            country = countries['iso2c'],\n",
    "                            start='1980',\n",
    "                            end='2024')\n",
    "# получаем название России в номенклатуре iso2c\n",
    "country_idx = le_data_all.index.levels[0]\n",
    "iso_rus_name = country_idx[country_idx.str.contains('ussian')][0]\n",
    "\n",
    "# получаем 2 способами значения для России\n",
    "le_data_all.loc[iso_rus_name], # le_data_all.xs(iso_rus_name, )\n",
    "\n",
    "# le_data_all.loc[iso_rus_name, ][::-1].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем выполнить разные интересные манипуляции с этими данными.\n",
    "В примере, рассмотренном ниже, мы для каждого года определяем страну с самой низкой продолжительностью жизни. Чтобы выполнить эту операцию, сначала нужно перевернуть (транспонировать) эти данные, чтобы индексом стало название страны, а годом стал столбец.\n",
    "\n",
    "Более подробно транспонирование данных мы рассмотрим в последующих главах, а пока вам важно просто знать, что следующий программный код преобразует страны в индекс, а годы – в столбцы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                            SP.DYN.LE00.IN                                      \n",
       "year                                  2019       2020       2021       2022 2023\n",
       "country                                                                         \n",
       "Afghanistan                      63.565000  62.575000  61.982000  62.879000  NaN\n",
       "Africa Eastern and Southern      63.754752  63.309794  62.449093  62.888463  NaN\n",
       "Africa Western and Central       57.500295  57.180671  56.946475  57.589106  NaN\n",
       "Albania                          79.282000  76.989000  76.463000  76.833000  NaN\n",
       "Algeria                          76.474000  74.453000  76.377000  77.129000  NaN"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_data = le_data_all.reset_index().pivot(index='country', columns='year')\n",
    "\n",
    "le_data.iloc[:5, -5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получив данные в таком формате, мы можем для каждого года определить\n",
    "страну с наименьшей продолжительностью жизни, воспользовавшись параметром <mark>.idxmin(axis=0)</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                year\n",
       " SP.DYN.LE00.IN  1980    Timor-Leste\n",
       "                 1981    Timor-Leste\n",
       "                 1982    Timor-Leste\n",
       "                 1983    Timor-Leste\n",
       "                 1984    South Sudan\n",
       " dtype: object,\n",
       " Index(['1980', '1981', '1982', '1983', '1984', '1985', '1986', '1987', '1988', '1989',\n",
       "        '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999',\n",
       "        '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009',\n",
       "        '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019',\n",
       "        '2020', '2021', '2022', '2023'],\n",
       "       dtype='object', name='year'))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# определяем для каждого года страну с наименьшей продолжительностью жизни\n",
    "# возращает по каждой колонке (в нашем слуыае это годы) значение индекса (в нашем случыае это\n",
    "# название страны) строки с минимальным значением в данной колонке.\n",
    "country_with_least_expectance = le_data.idxmin(axis=0)\n",
    "country_with_least_expectance[:5], country_with_least_expectance.index.levels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Минимальное значение продолжительности жизни для каждого года можно\n",
    "получить с помощью <mark>.min(axis=0)</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                year\n",
       " SP.DYN.LE00.IN  1980    28.446\n",
       "                 1981    29.567\n",
       "                 1982    30.824\n",
       "                 1983    31.635\n",
       "                 1984    32.673\n",
       " dtype: float64,\n",
       " Index(['1980', '1981', '1982', '1983', '1984', '1985', '1986', '1987', '1988', '1989',\n",
       "        '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999',\n",
       "        '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009',\n",
       "        '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019',\n",
       "        '2020', '2021', '2022', '2023'],\n",
       "       dtype='object', name='year'))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# определяем для каждого года минимальное значение продолжительности жизни\n",
    "expectancy_for_least_country = le_data.min(axis=0)\n",
    "expectancy_for_least_country[:5], expectancy_for_least_country.index.levels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем эти два результата можно объединить в новый датафрейм, в котором по\n",
    "каждому году будет приведена информация о стране с наименьшей продолжительностью жизни и минимальном значении продолжительности жизни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          Country  Expectancy\n",
       "year                         \n",
       "1980  Timor-Leste      28.446\n",
       "1981  Timor-Leste      29.567\n",
       "1982  Timor-Leste      30.824\n",
       "1983  Timor-Leste      31.635\n",
       "1984  South Sudan      32.673\n",
       "...           ...         ...\n",
       "2019      Nigeria      52.910\n",
       "2020         Chad      52.777\n",
       "2021         Chad      52.525\n",
       "2022         Chad      52.997\n",
       "2023          NaN         NaN\n",
       "\n",
       "[44 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# этот программный код объединяет два датафрейма вместе, и мы получаем\n",
    "# по каждому году страну с наименьшей продолжительностью жизни\n",
    "# и наименьшее значение продолжительности жизни\n",
    "least = pd.DataFrame(\n",
    "    data = {'Country': country_with_least_expectance.values,\n",
    "          'Expectancy': expectancy_for_least_country.values},\n",
    "    index = country_with_least_expectance.index.levels[1]\n",
    ")\n",
    "least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
