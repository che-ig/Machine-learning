{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки numpy и pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# импортируем библиотеку datetime для работы с датами\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Задаем некоторые опции библиотеки pandas, которые настраивают вывод\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 10) \n",
    "pd.set_option('display.max_rows', 15)\n",
    "pd.set_option('display.width', 90)\n",
    "\n",
    "# импортируем библиотеку matplotlib для построения графиков\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Исследование CSV-файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "['7/21/2014', '83.46', '83.53', '81.81', '81.93', '2359300']\n",
      "['7/18/2014', '83.3', '83.4', '82.52', '83.35', '4020800']\n",
      "['7/17/2014', '84.35', '84.63', '83.33', '83.63', '1974000']\n",
      "['7/16/2014', '83.77', '84.91', '83.66', '84.91', '1755600']\n",
      "['7/15/2014', '84.3', '84.38', '83.2', '83.58', '1874700']\n"
     ]
    }
   ],
   "source": [
    "# с помощью модуля csv взглянем на первые 5 строк CSV-файла\n",
    "import csv\n",
    " \n",
    "with open('Notebooks/Data/msft.csv') as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    for i, row in enumerate(reader): \n",
    "        print(row)\n",
    "        if(i >= 5):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "4  7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываеми msft.csv в датафрейм\n",
    "msft = pd.read_csv('Notebooks/Data/msft.csv')\n",
    "msft[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Open   High    Low  Close   Volume\n",
       "Date                                          \n",
       "7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# зададим индекс для наших данных. В нашем случае выберем 0 столбец (столбец с датой).\n",
    "msft = pd.read_csv('Notebooks/Data/msft.csv', index_col=0)\n",
    "msft[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open      float64\n",
       "High      float64\n",
       "Low       float64\n",
       "Close     float64\n",
       "Volume      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вывод и спецификаация типа данных (.dtypes)\n",
    "msft.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы принудительно задать тип столбца, воспользуйтесь параметром **dtype**\n",
    "функции pd.read_csv(). Следующий программный код преобразует столбец Volume\n",
    "в тип float64:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date       object\n",
       "Open      float64\n",
       "High      float64\n",
       "Low       float64\n",
       "Close     float64\n",
       "Volume    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# указываем, что столбец Volume должен иметь тип float64\n",
    "msft = pd.read_csv('Notebooks/Data/msft.csv', dtype = {'Volume': np.float64})\n",
    "msft.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Указание имен столбцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        date   open   high    low  close   volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "4  7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# задаем новый набор имен для столбцов\n",
    "# все имеют нижний регистр, header=0 задает строку заголовков\n",
    "df = pd.read_csv(\"Notebooks/Data/msft.csv\",\n",
    "                header=0,\n",
    "                names=['date', 'open', 'high', 'low', 'close', 'volume'])\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Указание конкретных столбцов для загрузки (usecols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           Close\n",
       "Date            \n",
       "7/21/2014  81.93\n",
       "7/18/2014  83.35\n",
       "7/17/2014  83.63\n",
       "7/16/2014  84.91\n",
       "7/15/2014  83.58"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"Notebooks/Data/msft.csv\",\n",
    "                 usecols=['Date', 'Close'],\n",
    "                index_col=['Date'])\n",
    "df2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сохранение датафрейма в CSV-файл\n",
    "С помощью метода <mark>.to_csv()</mark> объект DataFrame можно сохранить в CSV-файл.\n",
    "\n",
    "С помощью параметра **index_label='date'** необходимо указать, что именем индекса будет имя столбца date. В противном случае индекс не получит имени, добавляемого в первую строку файла, и это затруднит правильное чтение данных. \n",
    "**на данный момнет, кажется, нет необходимости задавать поле index_label т.к pandas и так оставляет индкесный столбец вместе с его меткой**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем датафрейм df2 в новый csv-файл\n",
    "# задаем имя индекса как date\n",
    "df2.to_csv('./msft_mofified.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'Close']\n",
      "['7/21/2014', '81.93']\n",
      "['7/18/2014', '83.35']\n",
      "['7/17/2014', '83.63']\n",
      "['7/16/2014', '84.91']\n",
      "['7/15/2014', '83.58']\n"
     ]
    }
   ],
   "source": [
    "# с помощью модуля csv взглянем на первые 5 строк CSV-файла\n",
    "with open('./msft_mofified.csv') as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    for i,row in enumerate(reader):\n",
    "        print(row)\n",
    "        if(i >= 5):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Работа с данными, в которых используются разделители полей\n",
    "Библиотека pandas предлагает функцию <mark>pd.read_table()</mark> для упрощения чтения\n",
    "данных с разделителями полей. В следующем примере эта функция используется\n",
    "для чтения файла данных msft, задав запятую в качестве значения параметра sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['|Date|Open|High|Low|Close|Volume']\n",
      "['0|7/21/2014|83.46|83.53|81.81|81.93|2359300']\n",
      "['1|7/18/2014|83.3|83.4|82.52|83.35|4020800']\n",
      "['2|7/17/2014|84.35|84.63|83.33|83.63|1974000']\n",
      "['3|7/16/2014|83.77|84.91|83.66|84.91|1755600']\n",
      "['4|7/15/2014|84.3|84.38|83.2|83.58|1874700']\n"
     ]
    }
   ],
   "source": [
    "# используем функцию read_table с параметром sep=',', чтобы прочитать CSV-файл\n",
    "df = pd.read_table(\"Notebooks/Data/msft.csv\", sep=',')\n",
    "\n",
    "df.to_csv('./msft_piped.txt', sep='|')\n",
    "# смотрим, как сработал метод\n",
    "with open('./msft_piped.txt') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        print(row)\n",
    "        if (i >= 5):\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обработка загрязненных данных\n",
    "Данные с разделителями полей могут содержать посторонние строки в начале или\n",
    "в конце файла. В качестве примеров можно привести служебную информацию,\n",
    "размещаемую вверху, например номер счета, адреса, сводные данные, размещаемые внизу. Кроме того, бывают случаи, когда данные хранятся в нескольких строках. Эти ситуации могут вызвать ошибки при загрузке данных. Чтобы разрешить\n",
    "такие ситуации, методы <mark>pd.read_csv и pd.read_table()</mark> предлагают некоторые полезные параметры, которые выручат нас.\n",
    "\n",
    "Опции <mark>skiprows и skipfooter</mark> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is fun because the data does not start on the first line', '', '', '', '', '']\n",
      "['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "['', '', '', '', '', '']\n",
      "['And there is space between the header row and data', '', '', '', '', '']\n",
      "['7/21/2014', '83.46', '83.53', '81.81', '81.93', '2359300']\n",
      "['7/18/2014', '83.3', '83.4', '82.52', '83.35', '4020800']\n"
     ]
    }
   ],
   "source": [
    "# смотрим первые 6 строк в файле msft2.csv\n",
    "with open('Notebooks/Data/msft2.csv') as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        print(row)\n",
    "        if(i >= 5):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        Date   Open   High    Low  Close   Volume\n",
       " 0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       " 1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       " 2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       " 3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       " 4  7/15/2014  84.30  84.38  83.20  83.58  1874700,\n",
       "         Date   Open   High    Low  Close   Volume\n",
       " 0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       " 1  7/18/2014  83.30  83.40  82.52  83.35  4020800)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считываем только нужные строки (убираем строки 0, 2, 3)\n",
    "df = pd.read_csv('Notebooks/Data/msft2.csv', skiprows=[0,2,3])\n",
    "\n",
    "# Для игнорирования последних строк файла есть опция skipfooter\n",
    "df2 = pd.read_csv('Notebooks/Data/msft_with_footer.csv', skipfooter=2, engine='python')\n",
    "df[:5], df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Если файл очень большой, а нам нужно прочитать только первые несколько строк,\n",
    "# то для этого есть опция nrows\n",
    "pd.read_csv('Notebooks/Data/msft.csv', nrows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        date   open   high    low  close      vol\n",
       "0   3/3/2014  80.35  81.31  79.91  79.97  5004100\n",
       "1  2/28/2014  82.40  83.42  82.17  83.42  2853200\n",
       "2  2/27/2014  84.06  84.63  81.63  82.00  3676800\n",
       "3  2/26/2014  82.92  84.03  82.43  83.81  2623600\n",
       "4  2/25/2014  83.80  83.80  81.72  83.08  3579100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пропускаем 100 строк, а затем считываем следующие 5 строк.\n",
    "# Т.к мы пропускаем строку с заголовком столбцщв, то необходимо сообщить pandas, чтобы она\n",
    "# не искала заголовки и использовала указанные имена.\n",
    "pd.read_csv(\"Notebooks/Data/msft.csv\", \n",
    "            skiprows=100, \n",
    "            nrows=5,\n",
    "            header=0, # обязаны это задать т.к передаем опцию names\n",
    "            names=['date', 'open', 'high', 'low', 'close', 'vol'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Чтение и запись данных в формате excex\n",
    "\n",
    "Библиотека pandas поддерживает чтение данных в формате Excel 2003 и более\n",
    "поздних форматах с помощью функции pd.read_excel() или класса ExcelFile. Оба\n",
    "способа используют либо пакет XLRD, либо пакет OpenPyXL, поэтому вам необходимо\n",
    "убедиться в том, что один из них установлен в вашей среде Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0 2014-07-21  83.46  83.53  81.81  81.93  2359300\n",
       "1 2014-07-18  83.30  83.40  82.52  83.35  4020800\n",
       "2 2014-07-17  84.35  84.63  83.33  83.63  1974000\n",
       "3 2014-07-16  83.77  84.91  83.66  84.91  1755600\n",
       "4 2014-07-15  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем файл excel\n",
    "# считываем только данные первого рабочего листа\n",
    "# (msft в данном случае)\n",
    "df = pd.read_excel('Notebooks/Data/stocks.xlsx')\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close    Volume\n",
       "0 2014-07-21  94.99  95.00  93.72  93.94  38887700\n",
       "1 2014-07-18  93.62  94.74  93.02  94.43  49898600\n",
       "2 2014-07-17  95.03  95.28  92.57  93.09  57152000\n",
       "3 2014-07-16  96.97  97.10  94.74  94.78  53396300\n",
       "4 2014-07-15  96.80  96.85  95.03  95.32  45477900"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считываем данные рабочего листа aapl\n",
    "aapl = pd.read_excel('Notebooks/Data/stocks.xlsx', sheet_name='aapl')\n",
    "aapl[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним xls-файл в рабочем листе 'MSFT'\n",
    "# т.к для чтения xls файлов мы испльзуем пакет openpyxl, то мы должны его указать в опции engine/\n",
    "df.to_excel('stocks2.xls', engine='openpyxl', sheet_name='MSFT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы записать несколько датафреймов в один и тот же файл Excel, по одному\n",
    "объекту DataFrame на каждый рабочий лист, воспользуйтесь объектом **ExcelWriter**\n",
    "и ключевым словом with. ExcelWriter является частью библиотеки pandas, однако\n",
    "вам нужно убедиться в том, что он импортирован, поскольку данный объект от-\n",
    "сутствует в пространстве имен верхнего уровня библиотеки pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Записываем несколько рабочих листов\n",
    "# требуется класс ExcelWriter\n",
    "# необходимо указать engine, иначе не будет работать.\n",
    "with pd.ExcelWriter('all_stocks.xls', engine='openpyxl') as writer:\n",
    "    aapl.to_excel(writer, engine='openpyxl', sheet_name='AAPL')\n",
    "    df.to_excel(writer, engine='openpyxl', sheet_name='MSFT')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Чтение и запись JSON-файлов\n",
    "\n",
    "Библиотека pandas может читать и записывать данные, хранящиеся в формате JavaScript Object Notation (JSON)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Close': {'0': 81.93, '1': 83.35, '2': 83.63, '3': 84.91, '4': 83.58},\n",
      " 'Date': {'0': 1405900800000,\n",
      "          '1': 1405641600000,\n",
      "          '2': 1405555200000,\n",
      "          '3': 1405468800000,\n",
      "          '4': 1405382400000},\n",
      " 'High': {'0': 83.53, '1': 83.4, '2': 84.63, '3': 84.91, '4': 84.38},\n",
      " 'Low': {'0': 81.81, '1': 82.52, '2': 83.33, '3': 83.66, '4': 83.2},\n",
      " 'Open': {'0': 83.46, '1': 83.3, '2': 84.35, '3': 83.77, '4': 84.3},\n",
      " 'Volume': {'0': 2359300,\n",
      "            '1': 4020800,\n",
      "            '2': 1974000,\n",
      "            '3': 1755600,\n",
      "            '4': 1874700}}\n"
     ]
    }
   ],
   "source": [
    "# записываем данные Excel в JSON-файл\n",
    "df[:5].to_json('stocks.json')\n",
    "\n",
    "# теперь посмотим на json файл\n",
    "import json\n",
    "\n",
    "# модуль для красивого вывода структурированных данных.\n",
    "from pprint import pprint\n",
    "\n",
    "with open('stocks.json') as data_file:\n",
    "    data = json.load(data_file)\n",
    "\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные в формате JSON можно прочитать с помощью функции pd.read_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0 2014-07-21  83.46  83.53  81.81  81.93  2359300\n",
       "1 2014-07-18  83.30  83.40  82.52  83.35  4020800\n",
       "2 2014-07-17  84.35  84.63  83.33  83.63  1974000\n",
       "3 2014-07-16  83.77  84.91  83.66  84.91  1755600\n",
       "4 2014-07-15  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считываем данные в формате JSON\n",
    "df_from_json = pd.read_json('stocks.json')\n",
    "df_from_json[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Чтение HTML-файлов из интернета\n",
    "Библиотека pandas поддерживает чтение HTML-файлов (или HTML-файлов с URL-адресов). Внутри библиотека pandas использует пакеты LXML, Html5Lib и BeautifulSoup4. Эти пакеты предлагают впечатляющие возможности для чтения и записи HTML-таблиц.\n",
    "\n",
    "Стандартный дистрибутив Anaconda может не включать эти пакеты. Если вы\n",
    "получаете ошибку, то, исходя из ее содержания, установите соответствующую\n",
    "библиотеку при помощи Anaconda Navigator. \n",
    "\n",
    "Кроме того, вы можете использовать pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'<meta http-equiv=\"refresh\" content=\"0;URL=\\'/resources/resolutions/bank-f'\n",
      " b'ailures/failed-bank-list/\\'\" />')\n"
     ]
    }
   ],
   "source": [
    "# Для иллюстрации мы считаем данные, представляющие собой список банков-\n",
    "# банкротов, опубликованный на сайте Федеральной корпорации по страхованию\n",
    "# вкладов по адресу https://www.fdic.gov/bank/individual/failed/banklist.html. \n",
    "# Просмотрев страницу, можно увидеть, что список обанкротившихся банков довольно внушителен.\n",
    "\n",
    "import requests\n",
    "\n",
    "# задаем URL-адрес HTML-файла\n",
    "url = \"http://www.fdic.gov/bank/individual/failed/banklist.html\"\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; rv:127.0) Gecko/20100101 Firefox/127.0',\n",
    "          'Host': 'www.fdic.gov',\n",
    "          'Accept':\t'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
    "          'Cookie':\n",
    "\t's_fid=1F29653C0E1665CD-0EDDE3127FCA1B33; s_pv=FDIC%3A%20Failed%20Bank%20List; s_cc=true; s_ppvl=FDIC%253A%2520Failed%2520Bank%2520List%2C2%2C2%2C694%2C2560%2C694%2C2560%2C694%2C2%2CP; s_ppv=FDIC%253A%2520Failed%2520Bank%2520List%2C58%2C2%2C1022%2C1891%2C423%2C1891%2C423%2C2%2CP'}\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# читаем его\n",
    "# , attrs={'id': 'DataTables_Table_0'}\n",
    "# banks = pd.read_html(url)\n",
    "# banks = pd.read_html(response.content)[0]\n",
    "# stocks = pd.read_html('Notebooks/Data/stocks.html')\n",
    "pprint(response.content)\n",
    "# проверяем как было прочитана часть первой таблицы\n",
    "# banks[0][0:5].iloc[:,0:2]\n",
    "# banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
