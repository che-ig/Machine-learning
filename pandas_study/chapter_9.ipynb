{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки numpy и pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# импортируем библиотеку datetime для работы с датами\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Задаем некоторые опции библиотеки pandas, которые настраивают вывод\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 10) \n",
    "pd.set_option('display.max_rows', 15)\n",
    "pd.set_option('display.width', 90)\n",
    "\n",
    "# импортируем библиотеку matplotlib для построения графиков\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Исследование CSV-файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "['7/21/2014', '83.46', '83.53', '81.81', '81.93', '2359300']\n",
      "['7/18/2014', '83.3', '83.4', '82.52', '83.35', '4020800']\n",
      "['7/17/2014', '84.35', '84.63', '83.33', '83.63', '1974000']\n",
      "['7/16/2014', '83.77', '84.91', '83.66', '84.91', '1755600']\n",
      "['7/15/2014', '84.3', '84.38', '83.2', '83.58', '1874700']\n"
     ]
    }
   ],
   "source": [
    "# с помощью модуля csv взглянем на первые 5 строк CSV-файла\n",
    "import csv\n",
    " \n",
    "with open('Notebooks/Data/msft.csv') as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    for i, row in enumerate(reader): \n",
    "        print(row)\n",
    "        if(i >= 5):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "4  7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываеми msft.csv в датафрейм\n",
    "msft = pd.read_csv('Notebooks/Data/msft.csv')\n",
    "msft[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Open   High    Low  Close   Volume\n",
       "Date                                          \n",
       "7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# зададим индекс для наших данных. В нашем случае выберем 0 столбец (столбец с датой).\n",
    "msft = pd.read_csv('Notebooks/Data/msft.csv', index_col=0)\n",
    "msft[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open      float64\n",
       "High      float64\n",
       "Low       float64\n",
       "Close     float64\n",
       "Volume      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вывод и спецификаация типа данных (.dtypes)\n",
    "msft.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы принудительно задать тип столбца, воспользуйтесь параметром **dtype**\n",
    "функции pd.read_csv(). Следующий программный код преобразует столбец Volume\n",
    "в тип float64:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date       object\n",
       "Open      float64\n",
       "High      float64\n",
       "Low       float64\n",
       "Close     float64\n",
       "Volume    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# указываем, что столбец Volume должен иметь тип float64\n",
    "msft = pd.read_csv('Notebooks/Data/msft.csv', dtype = {'Volume': np.float64})\n",
    "msft.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Указание имен столбцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        date   open   high    low  close   volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "4  7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# задаем новый набор имен для столбцов\n",
    "# все имеют нижний регистр, header=0 задает строку заголовков\n",
    "df = pd.read_csv(\"Notebooks/Data/msft.csv\",\n",
    "                header=0,\n",
    "                names=['date', 'open', 'high', 'low', 'close', 'volume'])\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Указание конкретных столбцов для загрузки (usecols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           Close\n",
       "Date            \n",
       "7/21/2014  81.93\n",
       "7/18/2014  83.35\n",
       "7/17/2014  83.63\n",
       "7/16/2014  84.91\n",
       "7/15/2014  83.58"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"Notebooks/Data/msft.csv\",\n",
    "                 usecols=['Date', 'Close'],\n",
    "                index_col=['Date'])\n",
    "df2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сохранение датафрейма в CSV-файл\n",
    "С помощью метода <mark>.to_csv()</mark> объект DataFrame можно сохранить в CSV-файл.\n",
    "\n",
    "С помощью параметра **index_label='date'** необходимо указать, что именем индекса будет имя столбца date. В противном случае индекс не получит имени, добавляемого в первую строку файла, и это затруднит правильное чтение данных. \n",
    "**на данный момнет, кажется, нет необходимости задавать поле index_label т.к pandas и так оставляет индкесный столбец вместе с его меткой**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем датафрейм df2 в новый csv-файл\n",
    "# задаем имя индекса как date\n",
    "df2.to_csv('./msft_mofified.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'Close']\n",
      "['7/21/2014', '81.93']\n",
      "['7/18/2014', '83.35']\n",
      "['7/17/2014', '83.63']\n",
      "['7/16/2014', '84.91']\n",
      "['7/15/2014', '83.58']\n"
     ]
    }
   ],
   "source": [
    "# с помощью модуля csv взглянем на первые 5 строк CSV-файла\n",
    "with open('./msft_mofified.csv') as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    for i,row in enumerate(reader):\n",
    "        print(row)\n",
    "        if(i >= 5):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Работа с данными, в которых используются разделители полей\n",
    "Библиотека pandas предлагает функцию <mark>pd.read_table()</mark> для упрощения чтения\n",
    "данных с разделителями полей. В следующем примере эта функция используется\n",
    "для чтения файла данных msft, задав запятую в качестве значения параметра sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['|Date|Open|High|Low|Close|Volume']\n",
      "['0|7/21/2014|83.46|83.53|81.81|81.93|2359300']\n",
      "['1|7/18/2014|83.3|83.4|82.52|83.35|4020800']\n",
      "['2|7/17/2014|84.35|84.63|83.33|83.63|1974000']\n",
      "['3|7/16/2014|83.77|84.91|83.66|84.91|1755600']\n",
      "['4|7/15/2014|84.3|84.38|83.2|83.58|1874700']\n"
     ]
    }
   ],
   "source": [
    "# используем функцию read_table с параметром sep=',', чтобы прочитать CSV-файл\n",
    "df = pd.read_table(\"Notebooks/Data/msft.csv\", sep=',')\n",
    "\n",
    "df.to_csv('./msft_piped.txt', sep='|')\n",
    "# смотрим, как сработал метод\n",
    "with open('./msft_piped.txt') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        print(row)\n",
    "        if (i >= 5):\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обработка загрязненных данных\n",
    "Данные с разделителями полей могут содержать посторонние строки в начале или\n",
    "в конце файла. В качестве примеров можно привести служебную информацию,\n",
    "размещаемую вверху, например номер счета, адреса, сводные данные, размещаемые внизу. Кроме того, бывают случаи, когда данные хранятся в нескольких строках. Эти ситуации могут вызвать ошибки при загрузке данных. Чтобы разрешить\n",
    "такие ситуации, методы <mark>pd.read_csv и pd.read_table()</mark> предлагают некоторые полезные параметры, которые выручат нас.\n",
    "\n",
    "Опции <mark>skiprows и skipfooter</mark> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is fun because the data does not start on the first line', '', '', '', '', '']\n",
      "['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "['', '', '', '', '', '']\n",
      "['And there is space between the header row and data', '', '', '', '', '']\n",
      "['7/21/2014', '83.46', '83.53', '81.81', '81.93', '2359300']\n",
      "['7/18/2014', '83.3', '83.4', '82.52', '83.35', '4020800']\n"
     ]
    }
   ],
   "source": [
    "# смотрим первые 6 строк в файле msft2.csv\n",
    "with open('Notebooks/Data/msft2.csv') as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        print(row)\n",
    "        if(i >= 5):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        Date   Open   High    Low  Close   Volume\n",
       " 0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       " 1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       " 2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       " 3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       " 4  7/15/2014  84.30  84.38  83.20  83.58  1874700,\n",
       "         Date   Open   High    Low  Close   Volume\n",
       " 0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       " 1  7/18/2014  83.30  83.40  82.52  83.35  4020800)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считываем только нужные строки (убираем строки 0, 2, 3)\n",
    "df = pd.read_csv('Notebooks/Data/msft2.csv', skiprows=[0,2,3])\n",
    "\n",
    "# Для игнорирования последних строк файла есть опция skipfooter\n",
    "df2 = pd.read_csv('Notebooks/Data/msft_with_footer.csv', skipfooter=2, engine='python')\n",
    "df[:5], df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Если файл очень большой, а нам нужно прочитать только первые несколько строк,\n",
    "# то для этого есть опция nrows\n",
    "pd.read_csv('Notebooks/Data/msft.csv', nrows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        date   open   high    low  close      vol\n",
       "0   3/3/2014  80.35  81.31  79.91  79.97  5004100\n",
       "1  2/28/2014  82.40  83.42  82.17  83.42  2853200\n",
       "2  2/27/2014  84.06  84.63  81.63  82.00  3676800\n",
       "3  2/26/2014  82.92  84.03  82.43  83.81  2623600\n",
       "4  2/25/2014  83.80  83.80  81.72  83.08  3579100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пропускаем 100 строк, а затем считываем следующие 5 строк.\n",
    "# Т.к мы пропускаем строку с заголовком столбцщв, то необходимо сообщить pandas, чтобы она\n",
    "# не искала заголовки и использовала указанные имена.\n",
    "pd.read_csv(\"Notebooks/Data/msft.csv\", \n",
    "            skiprows=100, \n",
    "            nrows=5,\n",
    "            header=0, # обязаны это задать т.к передаем опцию names\n",
    "            names=['date', 'open', 'high', 'low', 'close', 'vol'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Чтение и запись данных в формате excex\n",
    "\n",
    "Библиотека pandas поддерживает чтение данных в формате Excel 2003 и более\n",
    "поздних форматах с помощью функции pd.read_excel() или класса ExcelFile. Оба\n",
    "способа используют либо пакет XLRD, либо пакет OpenPyXL, поэтому вам необходимо\n",
    "убедиться в том, что один из них установлен в вашей среде Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0 2014-07-21  83.46  83.53  81.81  81.93  2359300\n",
       "1 2014-07-18  83.30  83.40  82.52  83.35  4020800\n",
       "2 2014-07-17  84.35  84.63  83.33  83.63  1974000\n",
       "3 2014-07-16  83.77  84.91  83.66  84.91  1755600\n",
       "4 2014-07-15  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем файл excel\n",
    "# считываем только данные первого рабочего листа\n",
    "# (msft в данном случае)\n",
    "df = pd.read_excel('Notebooks/Data/stocks.xlsx')\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close    Volume\n",
       "0 2014-07-21  94.99  95.00  93.72  93.94  38887700\n",
       "1 2014-07-18  93.62  94.74  93.02  94.43  49898600\n",
       "2 2014-07-17  95.03  95.28  92.57  93.09  57152000\n",
       "3 2014-07-16  96.97  97.10  94.74  94.78  53396300\n",
       "4 2014-07-15  96.80  96.85  95.03  95.32  45477900"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считываем данные рабочего листа aapl\n",
    "aapl = pd.read_excel('Notebooks/Data/stocks.xlsx', sheet_name='aapl')\n",
    "aapl[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним xls-файл в рабочем листе 'MSFT'\n",
    "# т.к для чтения xls файлов мы испльзуем пакет openpyxl, то мы должны его указать в опции engine/\n",
    "df.to_excel('stocks2.xls', engine='openpyxl', sheet_name='MSFT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы записать несколько датафреймов в один и тот же файл Excel, по одному\n",
    "объекту DataFrame на каждый рабочий лист, воспользуйтесь объектом **ExcelWriter**\n",
    "и ключевым словом with. ExcelWriter является частью библиотеки pandas, однако\n",
    "вам нужно убедиться в том, что он импортирован, поскольку данный объект от-\n",
    "сутствует в пространстве имен верхнего уровня библиотеки pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Записываем несколько рабочих листов\n",
    "# требуется класс ExcelWriter\n",
    "# необходимо указать engine, иначе не будет работать.\n",
    "with pd.ExcelWriter('all_stocks.xls', engine='openpyxl') as writer:\n",
    "    aapl.to_excel(writer, engine='openpyxl', sheet_name='AAPL')\n",
    "    df.to_excel(writer, engine='openpyxl', sheet_name='MSFT')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Чтение и запись JSON-файлов\n",
    "\n",
    "Библиотека pandas может читать и записывать данные, хранящиеся в формате JavaScript Object Notation (JSON)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Close': {'0': 81.93, '1': 83.35, '2': 83.63, '3': 84.91, '4': 83.58},\n",
      " 'Date': {'0': 1405900800000,\n",
      "          '1': 1405641600000,\n",
      "          '2': 1405555200000,\n",
      "          '3': 1405468800000,\n",
      "          '4': 1405382400000},\n",
      " 'High': {'0': 83.53, '1': 83.4, '2': 84.63, '3': 84.91, '4': 84.38},\n",
      " 'Low': {'0': 81.81, '1': 82.52, '2': 83.33, '3': 83.66, '4': 83.2},\n",
      " 'Open': {'0': 83.46, '1': 83.3, '2': 84.35, '3': 83.77, '4': 84.3},\n",
      " 'Volume': {'0': 2359300,\n",
      "            '1': 4020800,\n",
      "            '2': 1974000,\n",
      "            '3': 1755600,\n",
      "            '4': 1874700}}\n"
     ]
    }
   ],
   "source": [
    "# записываем данные Excel в JSON-файл\n",
    "df[:5].to_json('stocks.json')\n",
    "\n",
    "# теперь посмотим на json файл\n",
    "import json\n",
    "\n",
    "# модуль для красивого вывода структурированных данных.\n",
    "from pprint import pprint\n",
    "\n",
    "with open('stocks.json') as data_file:\n",
    "    data = json.load(data_file)\n",
    "\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные в формате JSON можно прочитать с помощью функции pd.read_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0 2014-07-21  83.46  83.53  81.81  81.93  2359300\n",
       "1 2014-07-18  83.30  83.40  82.52  83.35  4020800\n",
       "2 2014-07-17  84.35  84.63  83.33  83.63  1974000\n",
       "3 2014-07-16  83.77  84.91  83.66  84.91  1755600\n",
       "4 2014-07-15  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считываем данные в формате JSON\n",
    "df_from_json = pd.read_json('stocks.json')\n",
    "df_from_json[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Чтение HTML-файлов из интернета\n",
    "Библиотека pandas поддерживает чтение HTML-файлов (или HTML-файлов с URL-адресов). Внутри библиотека pandas использует пакеты LXML, Html5Lib и BeautifulSoup4. Эти пакеты предлагают впечатляющие возможности для чтения и записи HTML-таблиц.\n",
    "\n",
    "Стандартный дистрибутив Anaconda может не включать эти пакеты. Если вы\n",
    "получаете ошибку, то, исходя из ее содержания, установите соответствующую\n",
    "библиотеку при помощи Anaconda Navigator. \n",
    "\n",
    "Кроме того, вы можете использовать pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Bank NameBank       CityCity\n",
      "0  Republic First Bank dba Republic Bank   Philadelphia\n",
      "1                          Citizens Bank       Sac City\n",
      "2               Heartland Tri-State Bank        Elkhart\n",
      "3                    First Republic Bank  San Francisco\n",
      "4                         Signature Bank       New York\n"
     ]
    }
   ],
   "source": [
    "# Для иллюстрации мы считаем данные, представляющие собой список банков-\n",
    "# банкротов, опубликованный на сайте Федеральной корпорации по страхованию\n",
    "# вкладов по адресу https://www.fdic.gov/bank/individual/failed/banklist.html. \n",
    "# Просмотрев страницу, можно увидеть, что список обанкротившихся банков довольно внушителен.\n",
    "\n",
    "# import requests\n",
    "\n",
    "# задаем URL-адрес HTML-файла\n",
    "url = \"https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/\"\n",
    "\n",
    "# Можем воспользоваться пакетом resquests\n",
    "# response = requests.get(url)\n",
    "\n",
    "# читаем его\n",
    "banks = pd.read_html(url)\n",
    "# banks_2 = pd.read_html(response.content)\n",
    "\n",
    "# проверяем как было прочитана часть первой таблицы\n",
    "print(banks[0][0:5].iloc[:,0:2], end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода **.to_html()** объект DataFrame можно записать в HTML-файл.\n",
    "Этот метод создает файл, содержащий тег **\\<table\\>** для данных (а не весь HTML-\n",
    "документ). Следующий программный код записывает ранее прочитанные нами\n",
    "данные о котировках акций в HTML-файл и выводит полученный результат\n",
    "в браузере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считываем данные о котировках акций\n",
    "df = pd.read_excel('Notebooks/Data/stocks.xlsx')\n",
    "\n",
    "# Записываем первые 2 строки в HTML\n",
    "df.head(2).to_html('stocks.html')\n",
    "\n",
    "# Смотрим результат в браузере\n",
    "import webbrowser\n",
    "# webbrowser.open('./stocks.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Чтение и запись HDF5-файлов\n",
    "\n",
    "HDF5 – это модель данных, библиотека и файловый формат для хранения\n",
    "и управления данными. Он широко используется в научных вычислительных\n",
    "средах. HDF5 поддерживает неограниченное количество типов данных и предназначен для гибкого и эффективного ввода-вывода, а также для больших\n",
    "и сложных данных... **(стр. 180)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 22\u001b[0m\n\u001b[1;32m     17\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m     18\u001b[0m                 index\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mdate_range(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1/1/2000\u001b[39m\u001b[38;5;124m'\u001b[39m, periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m),\n\u001b[1;32m     19\u001b[0m                 columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# создаем хранилище HDF5\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHDFStore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNotebooks/Data/store.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# store['df'] = df # сохранение произошло здесь\u001b[39;00m\n\u001b[1;32m     24\u001b[0m store\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry-temp-R4LpgGoU-py3.10/lib/python3.10/site-packages/pandas/io/pytables.py:566\u001b[0m, in \u001b[0;36mHDFStore.__init__\u001b[0;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat is not a defined argument for HDFStore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 566\u001b[0m tables \u001b[38;5;241m=\u001b[39m \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtables\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m complib \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m complib \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tables\u001b[38;5;241m.\u001b[39mfilters\u001b[38;5;241m.\u001b[39mall_complibs:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplib only supports \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtables\u001b[38;5;241m.\u001b[39mfilters\u001b[38;5;241m.\u001b[39mall_complibs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m compression.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry-temp-R4LpgGoU-py3.10/lib/python3.10/site-packages/pandas/compat/_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    130\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing optional dependency \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstall_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextra\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse pip or conda to install \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstall_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry-temp-R4LpgGoU-py3.10/lib/python3.10/site-packages/tables/__init__.py:44\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlosc2 library not found. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m                        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI looked for \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(blosc2_search_paths)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Necessary imports to get versions stored on the cython extension\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilsextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_hdf5_version \u001b[38;5;28;01mas\u001b[39;00m _get_hdf5_version\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     48\u001b[0m hdf5_version \u001b[38;5;241m=\u001b[39m _get_hdf5_version()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/poetry-temp-R4LpgGoU-py3.10/lib/python3.10/site-packages/tables/utilsextension.pyx:1\u001b[0m, in \u001b[0;36minit tables.utilsextension\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "# задаем стартовое значение генератора случайных чисел\n",
    "# для получения воспроизводимых результатов\n",
    "np.random.seed(123456)\n",
    "\n",
    "# import h5py\n",
    "# def read_h5(file_name: str) -> None:\n",
    "#     with h5py.File('Notebooks/Data/store.h5', 'r') as f:\n",
    "#         # for key in f.keys():\n",
    "#         #     print(key)\n",
    "#         data = f['df']\n",
    "#         # data[:5]\n",
    "#         # print(data)\n",
    "#         print(dir(data), '\\n', data.get('/df').keys())\n",
    "#         print(data.get('/df')['axis1'][:])\n",
    "        \n",
    "# создаем датафрейм, состоящий из дат и случайных чисел, записанных в трех столбцах\n",
    "df = pd.DataFrame(np.random.randn(8, 3),\n",
    "                index=pd.date_range('1/1/2000', periods=8),\n",
    "                columns=['A', 'B', 'C'])\n",
    "\n",
    "# создаем хранилище HDF5\n",
    "store = pd.HDFStore(\"Notebooks/Data/store.h5\")\n",
    "# store['df'] = df # сохранение произошло здесь\n",
    "store\n",
    "# dset = f['df']\n",
    "# dset.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
